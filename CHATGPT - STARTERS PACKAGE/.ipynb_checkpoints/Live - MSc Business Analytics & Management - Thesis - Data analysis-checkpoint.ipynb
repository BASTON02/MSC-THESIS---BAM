{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1491cf8-8ecb-468d-8be8-006535bb2c26",
   "metadata": {},
   "source": [
    "## MSc Business Analytics & Management - Thesis - Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dc2a9-7cd2-4760-805a-bd37c03f686f",
   "metadata": {},
   "source": [
    "#### Authored by Benjamin Aston on 24/02/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05fe3a-a65e-4200-8f13-c592557dcf79",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589487f8-5a0c-40fc-9893-a48023da8d69",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1a052-f28c-4108-9124-3f4ebd198c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS ONE BEN AND DEBUG FROM CHAT\n",
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Ingest data\n",
    "configs = pd.read_csv(r\"C:\\Users\\benja\\Documents\\MSC BAM\\THESIS\\Gitrepo\\CHATGPT - STARTERS PACKAGE\\Real data\\All_configurations - Copy.csv\")\n",
    "execution_results = pd.read_csv(r\"C:\\Users\\benja\\Documents\\MSC BAM\\THESIS\\Gitrepo\\CHATGPT - STARTERS PACKAGE\\Real data\\Synthetic_Data_with_Execution_Time.csv\")\n",
    "\n",
    "# Configuration\n",
    "num_initial_tests = 6  # Number of initial test cases\n",
    "\n",
    "# Define search space\n",
    "db_memory_values = sorted(configs[\"DB_Memory\"].unique())\n",
    "mas_workers_values = sorted(configs[\"MAS_Workers\"].unique())\n",
    "parallel_jobs_values = sorted(configs[\"Parallel_Jobs\"].unique())\n",
    "\n",
    "# Perform Latin Hypercube Sampling (LHS)\n",
    "sampler = qmc.LatinHypercube(d=3, seed=42)\n",
    "lhs_samples = sampler.random(num_initial_tests)\n",
    "\n",
    "# Map LHS samples to discrete configuration values\n",
    "df_lhs_initial = pd.DataFrame({\n",
    "    \"DB_Memory\": [db_memory_values[int(i * len(db_memory_values))] for i in lhs_samples[:, 0]],\n",
    "    \"MAS_Workers\": [mas_workers_values[int(i * len(mas_workers_values))] for i in lhs_samples[:, 1]],\n",
    "    \"Parallel_Jobs\": [parallel_jobs_values[int(i * len(parallel_jobs_values))] for i in lhs_samples[:, 2]]\n",
    "})\n",
    "\n",
    "# Merge with actual configurations\n",
    "df_lhs_initial = df_lhs_initial.merge(configs, on=[\"DB_Memory\", \"MAS_Workers\", \"Parallel_Jobs\"], how=\"inner\")\n",
    "df_lhs_initial[\"Selection_Method\"] = \"LHS\"\n",
    "\n",
    "# Compute LHS selection metrics\n",
    "lhs_points = df_lhs_initial[[\"DB_Memory\", \"MAS_Workers\", \"Parallel_Jobs\"]].values\n",
    "pairwise_distances = pdist(lhs_points, metric='euclidean')\n",
    "\n",
    "lhs_metrics = {\n",
    "    \"Mean Pairwise Distance\": np.mean(pairwise_distances),\n",
    "    \"Coverage Score\": {\n",
    "        \"DB_Memory\": len(df_lhs_initial[\"DB_Memory\"].unique()) / len(db_memory_values),\n",
    "        \"MAS_Workers\": len(df_lhs_initial[\"MAS_Workers\"].unique()) / len(mas_workers_values),\n",
    "        \"Parallel_Jobs\": len(df_lhs_initial[\"Parallel_Jobs\"].unique()) / len(parallel_jobs_values)\n",
    "    },\n",
    "    \"Discrepancy Metric\": np.var(pairwise_distances)\n",
    "}\n",
    "\n",
    "#Manaully input execution time for LHS test cases\n",
    "# Assign execution times based on simulation mode\n",
    "if simulated:\n",
    "    df_lhs_initial[\"Execution_Time\"] = np.random.uniform(10, 100, size=len(df_lhs_initial))  # Generate random execution times\n",
    "else:\n",
    "    for index, row in df_lhs_initial.iterrows():\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = float(input(f\"Enter execution time for {row['Configuration']}: \"))\n",
    "                df_lhs_initial.at[index, \"Execution_Time\"] = user_input\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numeric execution time.\")\n",
    "\n",
    "# Display LHS results and metrics\n",
    "print(df_lhs_initial)\n",
    "lhs_metrics\n",
    "\n",
    "# Define a flag for simulation mode\n",
    "simulated = True  # Set to False for manual mode\n",
    "\n",
    "# Reset variables\n",
    "used_configs = set(df_lhs_initial[\"Configuration\"].unique())\n",
    "df_live_bo = df_lhs_initial.copy()\n",
    "print(df_lhs_initial)\n",
    "df_live_bo[\"Acquisition_Score\"] = np.nan\n",
    "df_available_configs = configs[~configs[\"Configuration\"].isin(used_configs)].copy()\n",
    "\n",
    "# BO Tracking Variables\n",
    "iteration_numbers = []\n",
    "acquisition_scores = []\n",
    "acquisition_history = []\n",
    "iteration = 1\n",
    "bo_selected_cases = []\n",
    "print(df_live_bo)\n",
    "while True:\n",
    "    print(f\"\\nðŸ”„ Starting Bayesian Optimization Iteration {iteration}...\")\n",
    "\n",
    "    # Update available configurations\n",
    "    df_available_configs = configs[~configs[\"Configuration\"].isin(used_configs)].copy()\n",
    "    \n",
    "    if df_available_configs.empty:\n",
    "        print(\"âœ… No more unique configurations left. Stopping BO.\")\n",
    "        break  \n",
    "\n",
    "    # Train Model\n",
    "    X_train = df_live_bo[[\"DB_Memory\", \"MAS_Workers\", \"Parallel_Jobs\"]].values\n",
    "    y_train = df_live_bo[\"Execution_Time\"].values\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Estimate Uncertainty\n",
    "    X_available_scaled = scaler.transform(df_available_configs[[\"DB_Memory\", \"MAS_Workers\", \"Parallel_Jobs\"]].values)\n",
    "    mean_prediction, std_prediction = estimate_uncertainty(rf, X_available_scaled)\n",
    "\n",
    "    # Compute Acquisition Score\n",
    "    acquisition_score = std_prediction + noise * np.random.rand(len(std_prediction))\n",
    "\n",
    "    # Select New Test Case\n",
    "    next_index = np.argmax(acquisition_score)\n",
    "    next_test_case = df_available_configs.iloc[next_index].copy()\n",
    "    used_configs.add(next_test_case[\"Configuration\"])\n",
    "    df_available_configs = df_available_configs.drop(df_available_configs.index[next_index])\n",
    "\n",
    "    # Determine Execution Time: Simulated or Manual\n",
    "    if simulated:\n",
    "        # Use synthetic execution time\n",
    "        next_test_case[\"Execution_Time\"] = execution_results.loc[\n",
    "            execution_results[\"Configuration\"] == next_test_case[\"Configuration\"], \"Execution_Time\"\n",
    "        ].values[0]\n",
    "    else:\n",
    "        # Request manual input for execution time\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = float(input(f\"Enter execution time for {next_test_case['Configuration']}: \"))\n",
    "                next_test_case[\"Execution_Time\"] = user_input\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numeric execution time.\")\n",
    "\n",
    "    # Assign BO Metadata\n",
    "    next_test_case[\"Selection_Method\"] = \"BO\"\n",
    "    next_test_case[\"Acquisition_Score\"] = acquisition_score[next_index]\n",
    "\n",
    "    # Store results\n",
    "    bo_selected_cases.append(next_test_case)\n",
    "    iteration_numbers.append(iteration)\n",
    "    acquisition_scores.append(acquisition_score[next_index])\n",
    "    acquisition_history.append(acquisition_score[next_index])\n",
    "\n",
    "    # Display progress plot after each iteration\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iteration_numbers, acquisition_scores, marker='o', linestyle='-', label=\"Acquisition Score\")\n",
    "    plt.axhline(y=tolerance_threshold, color='r', linestyle='--', label=\"Stopping Threshold\")\n",
    "    plt.xlabel(\"Iteration Number\")\n",
    "    plt.ylabel(\"Acquisition Score\")\n",
    "    plt.title(f\"Acquisition Score Over Bayesian Optimization Iterations (Iteration {iteration})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Check Stopping Criteria\n",
    "    if len(acquisition_history) >= N_average_tol and np.mean(acquisition_history[-N_average_tol:]) < tolerance_threshold:\n",
    "        print(f\"\\nâœ… Stopping criteria met at iteration {iteration}. Ending BO process.\")\n",
    "        break\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "# Convert BO Cases into DataFrame\n",
    "df_bo_cases = pd.DataFrame(bo_selected_cases)\n",
    "\n",
    "# Merge LHS and BO results\n",
    "df_live_bo = pd.concat([df_live_bo, df_bo_cases], ignore_index=True)\n",
    "\n",
    "# Display results\n",
    "print(df_live_bo)\n",
    "\n",
    "# Plot Acquisition Scores\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iteration_numbers, acquisition_scores, marker='o', linestyle='-', label=\"Acquisition Score\")\n",
    "plt.axhline(y=tolerance_threshold, color='r', linestyle='--', label=\"Stopping Threshold\")\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Acquisition Score\")\n",
    "plt.title(\"Acquisition Score Over Bayesian Optimization Iterations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec226a-9277-4a8d-9faf-9d26967604da",
   "metadata": {},
   "source": [
    "### Phase 2 - Bayesian optimisation using entropy and tuning how many explorations to run based on tolerance - Use data from previous test case to help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9bc74-4ae4-4bb0-a903-c74d03428d51",
   "metadata": {},
   "source": [
    "### Data cleaning of collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dca539-a81b-4337-9d0b-f8315d1f61c7",
   "metadata": {},
   "source": [
    "#### Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8e6a190f-8ac2-4fd8-9301-f2c1e7314b8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Synthetic_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Dummy setting of variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Synthetic_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(Synthetic_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDB_Memory\u001b[39m\u001b[38;5;124m\"\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Synthetic_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Dummy setting of variables\n",
    "Synthetic_data = pd.get_dummies(Synthetic_data, columns=[\"DB_Memory\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7b634-0c6b-45fe-810e-90e45e1b20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarise with skimpy\n",
    "skim(Synthetic_data)\n",
    "\n",
    "#Create report\n",
    "profile = ProfileReport(Synthetic_data, title=\"Synthetic_data Profiling Report\", explorative=True)\n",
    "\n",
    "# Save the report as an HTML file\n",
    "profile.to_file(\"Synthetic_data_profile_report.html\")\n",
    "\n",
    "#Use sweetviz for more summary reports\n",
    "report = sv.analyze(Synthetic_data)\n",
    "report.show_html(\"Synthetic_data_sweetviz_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb82263-452d-47f7-a399-7721c464ecac",
   "metadata": {},
   "source": [
    "#### Cleaning leading and na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e79796-ea8c-4dfd-9d52-94636109396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing whitespaces from values\n",
    "Synthetic_data.columns = Synthetic_data.columns.str.strip()\n",
    "\n",
    "#Count NAs in columns\n",
    "for col in Synthetic_data.columns:\n",
    "    na_count = Synthetic_data[col].isna().sum()\n",
    "    print(f\"Missing values in {col}: {na_count}\")\n",
    "\n",
    "#No missings, if there are any in the future, they need to be tackled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142f898-7d6d-4e1e-90b8-315d0e3b92e2",
   "metadata": {},
   "source": [
    "#### Outliers and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758563e-f758-4e98-a4dd-5019609e8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier analysis using Z scores\n",
    "for col in Numeric_cols:\n",
    "    z_scores = np.abs(stats.zscore(Synthetic_data[col]))\n",
    "    outliers = Synthetic_data[z_scores > 3]\n",
    "    print(outliers)\n",
    "\n",
    "#Category defined\n",
    "Synthetic_data['DB_Memory'] = Synthetic_data['DB_Memory'].astype('category')\n",
    "\n",
    "#Scale variables\n",
    "#Cols to not scale\n",
    "No_scale = [\"Configuration\",\"Execution_time\"]\n",
    "\n",
    "# Scale it into the same df\n",
    "columns_to_scale = [col for col in Synthetic_data.columns if col not in No_scale]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "Synthetic_data[columns_to_scale] = scaler.fit_transform(Synthetic_data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134a11a-575f-4b1d-9270-afa7a413563e",
   "metadata": {},
   "source": [
    "#### Causal analysis set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd5898-91e4-4c84-9651-5886b9270606",
   "metadata": {},
   "source": [
    "#### DoWhy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a432d3-30ee-4563-bfb5-901b5b55195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_causes = [\"DB_Memory\", \"MAS_Workers\",\"P\"] + \\\n",
    "    [col for col in Synthetic_data.columns if \"System_Memory\" in col or \"Database_Memory\" in col]\n",
    "\n",
    "model = CausalModel(\n",
    "    data=Synthetic_data,\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"Execution_Time\",\n",
    "    common_causes=common_causes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8f843-cbc2-41de-8387-8f3c6e7f1f2a",
   "metadata": {},
   "source": [
    "#### Show DAG based on set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c14e0b-1fe9-42b6-a082-3fa2c0cafea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directed Graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define bidirectional relationships (single thick blue arrows with two heads)\n",
    "edges_bidirectional = [\n",
    "    ('PARALLEL JOBS', 'DATABASE STORAGE'),\n",
    "    ('MAS WORKERS', 'DATABASE STORAGE'),\n",
    "    ('MAS WORKERS', 'PARALLEL JOBS')\n",
    "]\n",
    "\n",
    "# Define unidirectional relationships (single thin black arrows)\n",
    "edges_unidirectional = [\n",
    "    ('PARALLEL JOBS', 'EXECUTION TIME'),\n",
    "    ('DATABASE STORAGE', 'EXECUTION TIME'),\n",
    "    ('MAS WORKERS', 'EXECUTION TIME'),\n",
    "    ('JSON CHARACTERISTICS', 'EXECUTION TIME'),\n",
    "    ('JSON CHARACTERISTICS', 'MAS WORKERS'),\n",
    "    ('JSON CHARACTERISTICS', 'PARALLEL JOBS'),\n",
    "    ('JSON CHARACTERISTICS', 'DATABASE STORAGE')\n",
    "]\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edges_unidirectional)\n",
    "G.add_edges_from(edges_bidirectional)\n",
    "\n",
    "# Generate a position layout using 'kamada_kaway_layout' for better separation\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "# Assign colors: Red for 'Execution Time', White for 'JSON CHARACTERISTICS', Green for others\n",
    "node_colors = {\n",
    "    \"EXECUTION TIME\": \"red\",\n",
    "    \"JSON CHARACTERISTICS\": \"white\"\n",
    "}\n",
    "default_color = \"green\"\n",
    "node_color_list = [node_colors.get(node, default_color) for node in G.nodes()]\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_color_list, edgecolors=\"black\", node_size=2000, ax=ax)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=8, font_weight=\"bold\", ax=ax)\n",
    "\n",
    "# Draw bidirectional edges as a single thick blue line with two arrowheads\n",
    "for a, b in edges_bidirectional:\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[(a, b)], edge_color=\"blue\", width=3, ax=ax, arrows=True, arrowstyle='<->')\n",
    "\n",
    "# Draw unidirectional edges as thin black arrows\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges_unidirectional, edge_color=\"black\", width=1, ax=ax, arrows=True)\n",
    "\n",
    "# Set title\n",
    "plt.title(\"Causal DAG with Bidirectional (Blue) and Unidirectional Relationships (Black)\", fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce061909-5501-422c-99b9-84bc1b05914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the assumed causal graph\n",
    "model.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9fbfd7-4adb-4ec3-84da-a8dfed803b54",
   "metadata": {},
   "source": [
    "### M3E2 Neural Network or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b94eef-f851-4f73-b059-7d2f02818094",
   "metadata": {},
   "source": [
    "#### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bce33f-6337-4b76-b358-8bba89725dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
